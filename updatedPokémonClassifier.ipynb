{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pokemon Classifier - High Accuracy (Transfer Learning)\n",
    "\n",
    "This notebook implements a high-accuracy Pokemon classifier using Transfer Learning (MobileNetV2). \n",
    "It loads images directly from the folder structure, assuming each subfolder represents a class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print(f\"TensorFlow Version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration\n",
    "\n",
    "Define paths and hyperparameters. \n",
    "**NOTE:** Ensure your dataset is located at `DATASET_PATH` and contains subfolders for each Pokemon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Configuration\n",
    "IMG_SIZE = (224, 224) # MobileNetV2 expects 224x224\n",
    "CHANNELS = 3\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 20\n",
    "\n",
    "# Dataset Paths\n",
    "# The dataset should be in a folder named 'PokemonData' (or similar) containing subfolders for each class\n",
    "BASE_DIR = '.' # Current directory\n",
    "DATASET_PATH = os.path.join(BASE_DIR, 'dataset', 'PokemonData') \n",
    "\n",
    "print(f\"Dataset Path: {DATASET_PATH}\")\n",
    "\n",
    "if not os.path.exists(DATASET_PATH):\n",
    "    print(f\"WARNING: Dataset path not found at {DATASET_PATH}. Please check the path.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Visualization\n",
    "\n",
    "Let's visualize some sample images from the directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_samples(dataset_path, num_samples=9):\n",
    "    if not os.path.exists(dataset_path):\n",
    "        return\n",
    "\n",
    "    classes = [d for d in os.listdir(dataset_path) if os.path.isdir(os.path.join(dataset_path, d))]\n",
    "    if not classes:\n",
    "        print(\"No classes found.\")\n",
    "        return\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        # Pick a random class\n",
    "        cls = np.random.choice(classes)\n",
    "        cls_folder = os.path.join(dataset_path, cls)\n",
    "        images = os.listdir(cls_folder)\n",
    "        \n",
    "        if images:\n",
    "            # Pick a random image\n",
    "            img_name = np.random.choice(images)\n",
    "            img_path = os.path.join(cls_folder, img_name)\n",
    "            \n",
    "            try:\n",
    "                img = cv2.imread(img_path)\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                plt.subplot(3, 3, i + 1)\n",
    "                plt.imshow(img)\n",
    "                plt.title(cls)\n",
    "                plt.axis('off')\n",
    "            except Exception as e:\n",
    "                pass\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Uncomment to run if images are present\n",
    "# visualize_samples(DATASET_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Generators\n",
    "\n",
    "We use `ImageDataGenerator` with `flow_from_directory` to load images directly from folders. We split the data into 80% training and 20% validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation for Training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest',\n",
    "    validation_split=0.2 # Use 20% for validation\n",
    ")\n",
    "\n",
    "# Generators\n",
    "if os.path.exists(DATASET_PATH):\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        DATASET_PATH,\n",
    "        target_size=IMG_SIZE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='categorical',\n",
    "        subset='training', # Set as training data\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    val_generator = train_datagen.flow_from_directory(\n",
    "        DATASET_PATH,\n",
    "        target_size=IMG_SIZE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='categorical',\n",
    "        subset='validation', # Set as validation data\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    NUM_CLASSES = len(train_generator.class_indices)\n",
    "    print(f\"Number of classes: {NUM_CLASSES}\")\n",
    "else:\n",
    "    print(\"Dataset not found. Please check DATASET_PATH.\")\n",
    "    NUM_CLASSES = 151 # Default fallback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Architecture (Transfer Learning)\n",
    "\n",
    "We use **MobileNetV2** pre-trained on ImageNet as the base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(num_classes):\n",
    "    # Base Model (MobileNetV2)\n",
    "    base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3))\n",
    "    \n",
    "    # Freeze base model layers initially\n",
    "    base_model.trainable = False\n",
    "\n",
    "    # Custom Head\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    predictions = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    return model\n",
    "\n",
    "model = build_model(NUM_CLASSES)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training\n",
    "\n",
    "We use callbacks for Early Stopping and Learning Rate Reduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(DATASET_PATH):\n",
    "    # Callbacks\n",
    "    checkpoint = ModelCheckpoint(\n",
    "        'pokemon_classifier_model_V3.h5', \n",
    "        monitor='val_accuracy', \n",
    "        save_best_only=True, \n",
    "        mode='max',\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    reduce_lr = ReduceLROnPlateau(\n",
    "        monitor='val_loss', \n",
    "        factor=0.2, \n",
    "        patience=3, \n",
    "        min_lr=1e-6, \n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    early_stop = EarlyStopping(\n",
    "        monitor='val_loss', \n",
    "        patience=5, \n",
    "        restore_best_weights=True, \n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Train\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        epochs=EPOCHS,\n",
    "        validation_data=val_generator,\n",
    "        callbacks=[checkpoint, reduce_lr, early_stop]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluation & Fine-tuning\n",
    "\n",
    "Visualize training history and optionally fine-tune the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'history' in locals():\n",
    "    # Plot Accuracy and Loss\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs_range = range(len(acc))\n",
    "\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "    plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs_range, loss, label='Training Loss')\n",
    "    plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tuning (Optional)\n",
    "# Unfreeze the base model and train with a very low learning rate\n",
    "if os.path.exists(DATASET_PATH):\n",
    "    print(\"Starting Fine-tuning...\")\n",
    "    model.trainable = True\n",
    "    \n",
    "    # Recompile with low learning rate\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=1e-5),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    # Train for a few more epochs\n",
    "    history_fine = model.fit(\n",
    "        train_generator,\n",
    "        epochs=10,\n",
    "        validation_data=val_generator,\n",
    "        callbacks=[checkpoint, reduce_lr, early_stop]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save Final Model\n",
    "\n",
    "Save the final trained model for use in the Flask application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(DATASET_PATH):\n",
    "    model.save('pokemon_classifier_model_V3.h5')\n",
    "    print(\"Final model saved as pokemon_classifier_model_V3.h5\")\n",
    "    \n",
    "    # Save class indices for the Flask app\n",
    "    import json\n",
    "    class_indices = train_generator.class_indices\n",
    "    with open('class_indices.json', 'w') as f:\n",
    "        json.dump(class_indices, f)\n",
    "    print(\"Class indices saved as class_indices.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
