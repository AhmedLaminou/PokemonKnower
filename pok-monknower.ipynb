{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7340542,"sourceType":"datasetVersion","datasetId":2784626}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\n\n# 1️⃣ Set dataset paths\nPOKEMON_DATASET_PATH = '/kaggle/input/pokemon-generation-one-22k/PokemonData/'\n\n# 2️⃣ Optional sanity check\nif not os.path.exists(POKEMON_DATASET_PATH):\n    raise FileNotFoundError(f\"{POKEMON_DATASET_PATH} not found!\")\nprint(\"First Pokémon folders:\", os.listdir(POKEMON_DATASET_PATH)[:5])","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-12T23:49:54.673314Z","iopub.execute_input":"2025-10-12T23:49:54.673635Z","iopub.status.idle":"2025-10-12T23:49:54.679374Z","shell.execute_reply.started":"2025-10-12T23:49:54.673606Z","shell.execute_reply":"2025-10-12T23:49:54.678655Z"}},"outputs":[{"name":"stdout","text":"First Pokémon folders: ['Golbat', 'Beedrill', 'Caterpie', 'Clefable', 'Raichu']\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":" # Configuration variables (IMG_SIZE, batch size, etc.)\n\n\n\nIMG_SIZE = (80, 80)          # Resize images\nCHANNELS = 3                  # RGB images\nBATCH_SIZE = 32\nEPOCHS = 15\nVALIDATION_SPLIT = 0.2\n\nDATASET_PATH = '../input/pokemon-generation-one-22k/PokemonData/' \n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# data_preprocessing.py\n# Handles loading, preprocessing, augmentation\nimport os\nimport numpy as np\nimport cv2 as cv\nfrom sklearn.preprocessing import LabelEncoder\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# Configuration constants (moved from config.py)\nIMG_SIZE = (128, 128)\nCHANNELS = 3\nVALIDATION_SPLIT = 0.2\n\nimport pandas as pd\n\ndef load_dataset(dataset_path):\n    \"\"\"\n    Loads images and labels from dataset folder.\n    Assumes dataset structure: dataset_path/Pokemon_Name/*.jpg\n    \"\"\"\n    images, labels = [], []\n    types_list = []  # For multi-label type prediction\n    stats_list = []  # For regression (HP, Attack, etc.)\n\n    # Correct path to metadata CSV inside Kaggle dataset\n    metadata_path = os.path.join(os.path.dirname(dataset_path), 'pokemon_metadata.csv')\n    metadata = pd.read_csv(metadata_path)\n\n    for idx, row in metadata.iterrows():\n        img_path = os.path.join(dataset_path, row['Image'])\n        img = cv.imread(img_path)\n        if img is None:\n            continue\n        img = cv.resize(img, IMG_SIZE)\n        images.append(img)\n        labels.append(row['Name'])\n        types_list.append([row['Type1'], row.get('Type2', '')])  # some Pokémon have 2 types\n        stats_list.append([row['HP'], row['Attack'], row['Defense'], row['Sp. Atk'], row['Sp. Def'], row['Speed']])\n\n    images = np.array(images, dtype='float32') / 255.0\n    labels = np.array(labels)\n    stats_list = np.array(stats_list, dtype='float32')\n\n    # Encode Pokémon names\n    label_encoder = LabelEncoder()\n    labels_encoded = label_encoder.fit_transform(labels)\n    labels_encoded = to_categorical(labels_encoded)\n\n    return images, labels_encoded, types_list, stats_list, label_encoder\n\ndef create_datagen(x_train, y_train):\n    datagen = ImageDataGenerator(\n        rotation_range=15,\n        width_shift_range=0.1,\n        height_shift_range=0.1,\n        horizontal_flip=True,\n        validation_split=VALIDATION_SPLIT\n    )\n    train_gen = datagen.flow(x_train, y_train, batch_size=32, subset='training')\n    val_gen = datagen.flow(x_train, y_train, batch_size=32, subset='validation')\n    return train_gen, val_gen\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T23:55:10.564321Z","iopub.execute_input":"2025-10-12T23:55:10.564688Z","iopub.status.idle":"2025-10-12T23:55:10.574108Z","shell.execute_reply.started":"2025-10-12T23:55:10.564666Z","shell.execute_reply":"2025-10-12T23:55:10.573278Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"  # Defines the multi-output CNN model# model_architecture.py\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n\ndef build_multi_task_cnn(img_size, channels, num_pokemon, num_types, num_stats):\n    \"\"\"\n    Builds a CNN with multi-task outputs:\n      - Classification (Pokémon name)\n      - Type prediction (multi-label)\n      - Stats regression\n    \"\"\"\n    inp = Input(shape=(img_size[0], img_size[1], channels))\n\n    x = Conv2D(32, (3,3), activation='relu', padding='same')(inp)\n    x = Conv2D(64, (3,3), activation='relu', padding='same')(x)\n    x = MaxPooling2D((2,2))(x)\n    x = Conv2D(128, (3,3), activation='relu', padding='same')(x)\n    x = MaxPooling2D((2,2))(x)\n    x = Flatten()(x)\n    x = Dense(256, activation='relu')(x)\n    x = Dropout(0.5)(x)\n\n    # Pokémon classification\n    class_output = Dense(num_pokemon, activation='softmax', name='class_output')(x)\n\n    # Type prediction (multi-label)\n    type_output = Dense(num_types, activation='sigmoid', name='type_output')(x)\n\n    # Stats regression\n    stat_output = Dense(num_stats, activation='linear', name='stat_output')(x)\n\n    model = Model(inputs=inp, outputs=[class_output, type_output, stat_output])\n    return model\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T23:55:49.973440Z","iopub.execute_input":"2025-10-12T23:55:49.974115Z","iopub.status.idle":"2025-10-12T23:55:49.980117Z","shell.execute_reply.started":"2025-10-12T23:55:49.974089Z","shell.execute_reply":"2025-10-12T23:55:49.979355Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"# utils.py\n# Helper functions for visualization, splitting, etc.\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndef plot_image(img, title=''):\n    plt.imshow(img)\n    plt.title(title)\n    plt.axis('off')\n    plt.show()\n\ndef display_predictions(img, pred_class, pred_type, pred_stats, label_encoder):\n    print(\"Predicted Pokémon:\", label_encoder.inverse_transform([pred_class])[0])\n    print(\"Predicted Type(s):\", pred_type)\n    print(\"Predicted Stats:\", pred_stats)\n    plot_image(img)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# -------------------------------\n# Pokémon Multi-Task Training (No CSV)\n# -------------------------------\n\nimport os\nimport numpy as np\nimport cv2 as cv\nfrom sklearn.preprocessing import LabelEncoder\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout\nfrom tensorflow.keras.optimizers import Adam\n\n# -------------------------------\n# Config\n# -------------------------------\nIMG_SIZE = (128, 128)\nCHANNELS = 3\nBATCH_SIZE = 32\nEPOCHS = 10\nVALIDATION_SPLIT = 0.2\n\nDATASET_PATH = '/kaggle/input/pokemon-generation-one-22k/PokemonData'\n\n!ls /kaggle/input/pokemon-generation-one-22k/images/\n\n\n# -------------------------------\n# Data Loading\n# -------------------------------\ndef load_dataset(dataset_path, img_size=(128,128), channels=3):\n    \"\"\"\n    Loads images directly from folders.\n    Assumes dataset structure: dataset_path/Pokemon_Name/*.jpg\n    \"\"\"\n    images = []\n    labels = []\n\n    for pokemon_name in os.listdir(dataset_path):\n        pokemon_folder = os.path.join(dataset_path, pokemon_name)\n        if not os.path.isdir(pokemon_folder):\n            continue\n        for img_file in os.listdir(pokemon_folder):\n            img_path = os.path.join(pokemon_folder, img_file)\n            img = cv.imread(img_path)\n            if img is None:\n                continue\n            img = cv.resize(img, img_size)\n            images.append(img)\n            labels.append(pokemon_name)\n\n    images = np.array(images, dtype='float32') / 255.0\n    labels = np.array(labels)\n\n    # Encode Pokémon names\n    label_encoder = LabelEncoder()\n    labels_encoded = label_encoder.fit_transform(labels)\n    labels_encoded = to_categorical(labels_encoded)\n\n    return images, labels_encoded, label_encoder\n\n# Load dataset\nimages, labels_encoded, label_encoder = load_dataset(DATASET_PATH, img_size=IMG_SIZE, channels=CHANNELS)\nnum_pokemon = labels_encoded.shape[1]\n\n# For multi-task placeholders (if you want to add them later)\nnum_types = 18\nnum_stats = 6\ntypes_placeholder = np.random.rand(len(images), num_types)\nstats_placeholder = np.random.rand(len(images), num_stats)\n\n# -------------------------------\n# Model Architecture\n# -------------------------------\ndef build_multi_task_cnn(img_size, channels, num_pokemon, num_types, num_stats):\n    inp = Input(shape=(img_size[0], img_size[1], channels))\n    x = Conv2D(32, (3,3), activation='relu', padding='same')(inp)\n    x = Conv2D(64, (3,3), activation='relu', padding='same')(x)\n    x = MaxPooling2D((2,2))(x)\n    x = Conv2D(128, (3,3), activation='relu', padding='same')(x)\n    x = MaxPooling2D((2,2))(x)\n    x = Flatten()(x)\n    x = Dense(256, activation='relu')(x)\n    x = Dropout(0.5)(x)\n\n    class_output = Dense(num_pokemon, activation='softmax', name='class_output')(x)\n    type_output = Dense(num_types, activation='sigmoid', name='type_output')(x)\n    stat_output = Dense(num_stats, activation='linear', name='stat_output')(x)\n\n    model = Model(inputs=inp, outputs=[class_output, type_output, stat_output])\n    return model\n\n# -------------------------------\n# Build and Compile Model\n# -------------------------------\nmodel = build_multi_task_cnn(IMG_SIZE, CHANNELS, num_pokemon, num_types, num_stats)\nmodel.compile(\n    optimizer=Adam(learning_rate=0.001),\n    loss={\n        'class_output': 'categorical_crossentropy',\n        'type_output': 'binary_crossentropy',\n        'stat_output': 'mse'\n    },\n    metrics={'class_output': 'accuracy'}\n)\n\n# -------------------------------\n# Train Model\n# -------------------------------\nmodel.fit(\n    images,\n    {\n        'class_output': labels_encoded,\n        'type_output': types_placeholder,\n        'stat_output': stats_placeholder\n    },\n    batch_size=BATCH_SIZE,\n    epochs=EPOCHS,\n    validation_split=VALIDATION_SPLIT\n)\n\n# -------------------------------\n# Save Model\n# -------------------------------\nmodel.save('pokemon_multi_task_model.h5')\n\nprint(\"Training complete! Model saved as pokemon_multi_task_model.h5\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-13T00:08:49.973603Z","iopub.execute_input":"2025-10-13T00:08:49.974390Z","iopub.status.idle":"2025-10-13T00:21:50.244106Z","shell.execute_reply.started":"2025-10-13T00:08:49.974364Z","shell.execute_reply":"2025-10-13T00:21:50.243193Z"}},"outputs":[{"name":"stdout","text":"ls: cannot access '/kaggle/input/pokemon-generation-one-22k/images/': No such file or directory\n","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1760314626.192861      37 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\nI0000 00:00:1760314626.193542      37 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/10\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1760314639.296389     179 service.cc:148] XLA service 0x3a666b30 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1760314639.297377     179 service.cc:156]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\nI0000 00:00:1760314639.297408     179 service.cc:156]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\nI0000 00:00:1760314639.750956     179 cuda_dnn.cc:529] Loaded cuDNN version 90300\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m  4/503\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 47ms/step - class_output_accuracy: 0.0000e+00 - class_output_loss: 6.9595 - loss: 34.4744 - stat_output_loss: 26.3568 - type_output_loss: 1.1581","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1760314645.960873     179 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m503/503\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 67ms/step - class_output_accuracy: 0.0089 - class_output_loss: 5.0214 - loss: 7.0459 - stat_output_loss: 1.3054 - type_output_loss: 0.7191 - val_class_output_accuracy: 0.0000e+00 - val_class_output_loss: 7.8845 - val_loss: 8.6674 - val_stat_output_loss: 0.0906 - val_type_output_loss: 0.6936\nEpoch 2/10\n\u001b[1m503/503\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 49ms/step - class_output_accuracy: 0.0381 - class_output_loss: 4.5706 - loss: 5.3979 - stat_output_loss: 0.1310 - type_output_loss: 0.6963 - val_class_output_accuracy: 0.0000e+00 - val_class_output_loss: 14.0827 - val_loss: 14.8722 - val_stat_output_loss: 0.1024 - val_type_output_loss: 0.6940\nEpoch 3/10\n\u001b[1m503/503\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 49ms/step - class_output_accuracy: 0.1585 - class_output_loss: 3.5459 - loss: 4.3964 - stat_output_loss: 0.1538 - type_output_loss: 0.6967 - val_class_output_accuracy: 0.0000e+00 - val_class_output_loss: 18.4424 - val_loss: 19.2169 - val_stat_output_loss: 0.0930 - val_type_output_loss: 0.6940\nEpoch 4/10\n\u001b[1m503/503\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 50ms/step - class_output_accuracy: 0.2650 - class_output_loss: 2.9175 - loss: 3.7300 - stat_output_loss: 0.1160 - type_output_loss: 0.6965 - val_class_output_accuracy: 0.0000e+00 - val_class_output_loss: 20.2848 - val_loss: 21.0581 - val_stat_output_loss: 0.0895 - val_type_output_loss: 0.6940\nEpoch 5/10\n\u001b[1m503/503\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 52ms/step - class_output_accuracy: 0.3574 - class_output_loss: 2.4664 - loss: 3.2633 - stat_output_loss: 0.1000 - type_output_loss: 0.6969 - val_class_output_accuracy: 0.0000e+00 - val_class_output_loss: 24.7093 - val_loss: 25.4800 - val_stat_output_loss: 0.0870 - val_type_output_loss: 0.6949\nEpoch 6/10\n\u001b[1m503/503\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 52ms/step - class_output_accuracy: 0.4360 - class_output_loss: 2.0945 - loss: 2.8866 - stat_output_loss: 0.0948 - type_output_loss: 0.6973 - val_class_output_accuracy: 2.4876e-04 - val_class_output_loss: 27.2145 - val_loss: 27.9850 - val_stat_output_loss: 0.0874 - val_type_output_loss: 0.6946\nEpoch 7/10\n\u001b[1m503/503\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 51ms/step - class_output_accuracy: 0.4923 - class_output_loss: 1.8000 - loss: 2.5894 - stat_output_loss: 0.0922 - type_output_loss: 0.6972 - val_class_output_accuracy: 0.0012 - val_class_output_loss: 27.7580 - val_loss: 28.5225 - val_stat_output_loss: 0.0854 - val_type_output_loss: 0.6946\nEpoch 8/10\n\u001b[1m503/503\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 51ms/step - class_output_accuracy: 0.5571 - class_output_loss: 1.5371 - loss: 2.3283 - stat_output_loss: 0.0933 - type_output_loss: 0.6979 - val_class_output_accuracy: 0.0037 - val_class_output_loss: 28.1300 - val_loss: 28.9022 - val_stat_output_loss: 0.0856 - val_type_output_loss: 0.6943\nEpoch 9/10\n\u001b[1m503/503\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 51ms/step - class_output_accuracy: 0.6023 - class_output_loss: 1.3523 - loss: 2.1445 - stat_output_loss: 0.0941 - type_output_loss: 0.6981 - val_class_output_accuracy: 0.0027 - val_class_output_loss: 30.4922 - val_loss: 31.2592 - val_stat_output_loss: 0.0855 - val_type_output_loss: 0.6939\nEpoch 10/10\n\u001b[1m503/503\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 51ms/step - class_output_accuracy: 0.6336 - class_output_loss: 1.2067 - loss: 1.9991 - stat_output_loss: 0.0940 - type_output_loss: 0.6983 - val_class_output_accuracy: 0.0032 - val_class_output_loss: 33.2106 - val_loss: 33.9872 - val_stat_output_loss: 0.0860 - val_type_output_loss: 0.6941\nTraining complete! Model saved as pokemon_multi_task_model.h5\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"# -------------------------------\n# Pokémon Prediction Demo\n# -------------------------------\n\nimport os\nimport cv2 as cv\nimport numpy as np\nfrom tensorflow.keras.models import load_model\nfrom sklearn.preprocessing import LabelEncoder\nimport matplotlib.pyplot as plt\n\n# -------------------------------\n# Settings\n# -------------------------------\nDATASET_PATH = '/kaggle/input/pokemon-generation-one-22k/PokemonData/'\nMODEL_PATH = '/kaggle/working/pokemon_multi_task_model.h5'\nIMG_SIZE = (128, 128)  # Use same as training\nCHANNELS = 3\n\n# -------------------------------\n# Load model\n# -------------------------------\nmodel = load_model(MODEL_PATH, compile=False)\nprint(\"Model loaded.\")\n\n# -------------------------------\n# Build label encoder from folder names\n# -------------------------------\npokemon_names = sorted([d for d in os.listdir(DATASET_PATH) if os.path.isdir(os.path.join(DATASET_PATH, d))])\nlabel_encoder = LabelEncoder()\nlabel_encoder.fit(pokemon_names)\nprint(\"Label encoder ready with classes:\", pokemon_names[:10], \"...\")\n\n# -------------------------------\n# Utility function to plot image\n# -------------------------------\ndef plot_prediction(img_path, pred_class_idx):\n    img = cv.imread(img_path)\n    img_rgb = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n    plt.imshow(img_rgb)\n    plt.axis('off')\n    plt.title(\"Predicted: \" + label_encoder.inverse_transform([pred_class_idx])[0])\n    plt.show()\n\n# -------------------------------\n# Predict function\n# -------------------------------\ndef predict_image(img_path):\n    img = cv.imread(img_path)\n    if img is None:\n        print(\"Image not found:\", img_path)\n        return\n    img_resized = cv.resize(img, IMG_SIZE)\n    img_input = np.expand_dims(img_resized, axis=0) / 255.0\n    pred_class, pred_type, pred_stats = model.predict(img_input)\n    pred_class_idx = np.argmax(pred_class[0])\n    plot_prediction(img_path, pred_class_idx)\n    return pred_class_idx, pred_type[0], pred_stats[0]\n\n# -------------------------------\n# Test multiple images\n# -------------------------------\ntest_images = [\n    '/kaggle/input/pokemon-generation-one-22k/PokemonData/Abra/000-063Abra_RB.png',\n    '/kaggle/input/pokemon-generation-one-22k/PokemonData/Abra/004-063Abra_OS_anime_2.png',\n    '/kaggle/input/pokemon-generation-one-22k/PokemonData/Alakazam/000-065Alakazam_RB.png'\n]\n\nfor img_path in test_images:\n    predict_image(img_path)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"jupyter nbconvert --to script /kaggle/working/pokemon_project.ipynb\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}